% !TeX root = ../main.tex

\ustcsetup{
  keywords = {
    多智能体强化学习, 角色涌现,  星际争霸II, 深度学习
  },
  keywords* = {
    Multi-Agent Reinforcement Learning(MARL), Role Emergence, StarCraftII, Deep Learning
  },
}

\begin{abstract}
   在许多自然系统中，为了提高劳动的高效性，角色概念涌现出来了，同时，许多多智能系统也考虑使用角色概念来设计高效的组织形式。然而，在这些系统中，角色和相对应的责任会提前预定义。另一方面，在多智能体强化学习算法中，参数共享是被广泛采用的，但是在复杂的任务中，这种共享会显得很低效。尽管这两方面各自有缺陷，但是它们却能互相弥补对方。
   
   在本文中，一个基于角色的多智能体强化学习框架被提出来去解决这些缺点。在这个框架里，涌现的角色会专注于特定的子任务，同时策略和训练学习会动态地在那些拥有相似角色的智能体间共享。为了达到这个目的，本文引入了角色空间，即一个随机嵌入空间，并将个体的策略决定于它自己的角色，以及引入两个创新的损失函数来引导训练学习。实验也证明了本算法能够学到动态的、通用的、可识别的以及专业化的角色，这些都帮助了本算法拉高了星际争霸II微操作环境的最佳胜率。同时，在训练过程中角色的演化和涌现也为我们理解和促进智能体之间的协作提供了一个新视角。

\end{abstract}

\begin{enabstract}
  The role emerges as an important concept in many natural systems in terms of improving labor efficiency, and many multi-agent systems resort to the role notion to design efficient organizations. However, roles and the associated responsibilities are predefined in these systems. In another line of research, parameter sharing among agents is commonly adopted by multi-agent reinforcement learning (MARL) algorithms, which may be less efficient in complex task. Despite the individual shortcomings, these two fields complement each other. 
  
  In this paper, a role-oriented MARL framework (ROMA) that resolves these drawbacks is proposed. In this framework, emergent roles are encouraged to be specialized on certain sub-tasks, and policies are shared within dynamic groups consisting of agents with similar role. To this end, a stochastic role embedding space is constructed by introducing two novel regularizers and conditioning individual policies on roles. Experiments show that this method can learn dynamic, versatile, identifiable, and specialized roles, which help this method push forward the state of the art on StarCraft II micromanagement benchmark. The emergence and evolution process of roles during the training stage is further demonstrated to provide a new perspective on the understanding and promotion of the emergence of cooperation among agents.

\end{enabstract}
